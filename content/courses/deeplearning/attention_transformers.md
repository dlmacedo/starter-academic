---
title: Attention and Transformers
linktitle: Attention and Transformers
toc: true
type: docs
date: "2019-05-05T00:00:00+01:00"
draft: false
menu:
  example:
    parent: Main Course
    weight: 50

# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 50
---

{{< figure library="true" src="transformer2.png" >}}

### Slides

* [Attention and Transformers](https://drive.google.com/file/d/167ZjJNMrnBcJ0IyHD0XZY2gR3USobJ5K/view?usp=sharing)

### Code

* [PyTorch: Transformer Illustration and code](https://githubtocolab.com/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Transformer_Illustration_and_code.ipynb)

* [PyTorch: nn.Transformer Tutorial](https://githubtocolab.com/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/transformer_tutorial.ipynb)

* [PyTorch: Object Detection with DETR - a minimal implementation](https://githubtocolab.com/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/detr_demo.ipynb)

### Extra

* [Transformer: A Novel Neural Network Architecture for Language Understanding](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)

* [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)

* [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)

* [Transformers from Scratch](http://peterbloem.nl/blog/transformers)
