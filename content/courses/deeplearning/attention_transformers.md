---
title: Attention and Transformers
linktitle: Attention and Transformers
toc: true
type: docs
date: "2019-05-05T00:00:00+01:00"
draft: false
menu:
  example:
    parent: Main Course
    weight: 50

# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 50
---

{{< figure library="true" src="transformer2.png" >}}

### Lecture Video (Portuguese)

* [Attention and Transformers](https://drive.google.com/file/d/1Ljv2Wd_8DUTqpX7i9zC3qf5L7yqlwEiL/view?usp=sharing)

### Slides (English)

* [Attention and Transformers](https://drive.google.com/file/d/1U2z9JbWNeVAaTZhXKlrXlfFXriu8JMIp/view?usp=sharing)

### Code (Google Colab, Notebooks and More)

* [PyTorch: Transformer Illustration and code](https://githubtocolab.com/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Transformer_Illustration_and_code.ipynb)

* [PyTorch: nn.Transformer Tutorial](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/dca13261bbb4e9809d1a3aa521d22dd7/transformer_tutorial.ipynb)

* [PyTorch: Object Detection with DETR - a minimal implementation](https://githubtocolab.com/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/detr_demo.ipynb)

* [Hugging Face: Fine-tuning a pretrained model](https://huggingface.co/transformers/training.html)

* [Hugging Face: Transformers Notebooks](https://huggingface.co/transformers/notebooks.html)

* [Hugging Face: Examples](https://github.com/huggingface/transformers/tree/master/examples)

### Additional Resources

* [Transformer: A Novel Neural Network Architecture for Language Understanding](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)

* [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)

* [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)

* [Transformers from Scratch](http://peterbloem.nl/blog/transformers)
